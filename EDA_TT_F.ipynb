{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1637a4ff-47fb-42ad-99a2-8050d42dcff5",
   "metadata": {},
   "source": [
    "# **Proyecto Hackathon The Data Guys**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1764f-9ba2-4e21-8955-a5669a3ab70f",
   "metadata": {},
   "source": [
    "## Importación y carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffa8be4-17ad-48d5-bb14-269bd07318b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import silhouette_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e78cb4e-b5a1-405c-b499-ff0b43c0c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Online_Retail.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32360b5d-3bcd-4223-9a6f-60d436cce2d9",
   "metadata": {},
   "source": [
    "## Exploración del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5ceba-a9f0-4f36-84ad-bc0292447fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar y visualizar datos\n",
    "\n",
    "# Convertir todos los nombres de columnas a minúsculas\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Mostrar información general del DataFrame\n",
    "print(\"\\n 'Exploración del DF'\\n\")\n",
    "display(df.info())\n",
    "\n",
    "# Mostrar el número de valores nulos en cada columna\n",
    "print(\"\\n 'Valores Nulos'\\n\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Mostrar el número total de filas duplicadas\n",
    "print(\"\\n 'Valores Duplicados'\\n\")\n",
    "display(df.duplicated().sum())\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(\"\\n\\n 'Vista del DataFrame'\\n\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1c915-60db-4df0-8e83-51e7cd37c2c6",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e6e50-223f-486e-8aef-8a0ddca6b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejar valores nulos en 'customer_id'\n",
    "# Vamos a eliminar las filas sin customer_id, ya que no podemos hacer segmentación sin esta información\n",
    "df = df.dropna(subset=['customer_id'])\n",
    "\n",
    "# Verificar valores nulos nuevamente\n",
    "print(\"\\n Valores nulos actualizados\\n\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verificar duplicados nuevamente\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"Filas duplicadas después de la eliminación: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700979d5-5013-4e17-8475-6581eaa063b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'invoice_date' a datetime\n",
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'], format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "# Verificar el tipo de dato de 'invoice_date'\n",
    "print(df['invoice_date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f880b-c8ea-45f3-b687-60a481516e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abaa6d-2e44-4960-83d9-5e9b2dd28600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con cantidad o precio unitario negativos\n",
    "df = df[(df['quantity'] > 0) & (df['unit_price'] > 0)]\n",
    "\n",
    "# Verificar el rango de 'quantity' y 'unit_price'\n",
    "df[['quantity', 'unit_price']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff6b11-41b3-40e3-9f0d-ff7e1ef2e590",
   "metadata": {},
   "source": [
    "Estadísticas de quantity y unit_price:\n",
    "\n",
    "La cantidad media de artículos por orden es de 13.12, pero con una desviación estándar alta (180.49), lo que indica una gran variabilidad.\n",
    "El precio unitario medio es de 3.13, pero también con alta variabilidad (desviación estándar de 22.24).\n",
    "Hay algunos valores extremos, con un máximo de 80,995 para quantity y 8,142.75 para unit_price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cabd8-9354-4548-b7b5-2fa6729fa56d",
   "metadata": {},
   "source": [
    "### Análisis RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a2636-8c40-4332-8674-6b233e0f89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, asegurémonos de que 'customer_id' sea de tipo entero\n",
    "df['customer_id'] = df['customer_id'].astype(int)\n",
    "\n",
    "# Calcular el valor monetario total por transacción\n",
    "df['total_price'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "# Encontrar la fecha más reciente en el dataset\n",
    "max_date = df['invoice_date'].max()\n",
    "\n",
    "# Calcular RFM\n",
    "rfm = df.groupby('customer_id').agg({\n",
    "    'invoice_date': lambda x: (max_date - x.max()).days,  # Recency\n",
    "    'invoice_no': 'count',  # Frequency\n",
    "    'total_price': 'sum'  # Monetary\n",
    "})\n",
    "\n",
    "# Renombrar las columnas\n",
    "rfm.columns = ['recency', 'frequency', 'monetary']\n",
    "\n",
    "# Asegurarse de que 'monetary' no tenga valores negativos\n",
    "rfm = rfm[rfm['monetary'] > 0]\n",
    "\n",
    "# Mostrar las primeras filas del dataframe RFM\n",
    "display(rfm.head())\n",
    "\n",
    "# Mostrar estadísticas descriptivas del dataframe RFM\n",
    "display(rfm.describe())\n",
    "\n",
    "# Verificar si hay valores nulos en el dataframe RFM\n",
    "rfm.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e341fcd-8c12-481b-afe8-66003a90cfea",
   "metadata": {},
   "source": [
    "\n",
    "**Estadísticas RFM:**\n",
    "\n",
    "- Recency: La media es de 91.61 días, con un mínimo de 0 y un máximo de 374 días.\n",
    "- Frequency: En promedio, los clientes han realizado 90.52 compras, pero hay una gran variabilidad (desviación estándar de 225.51).\n",
    "- Monetary: El gasto promedio por cliente es de 2,048.69, pero con una desviación estándar muy alta (8,985.23), indicando una gran dispersión en el gasto.\n",
    "\n",
    "No hay valores nulos en las métricas RFM, lo cual es bueno para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af1aa3-e941-45e0-8474-9696f995cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610abb6-f17c-46fe-955a-48ce8f6dc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el estilo de las gráficas\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"deep\")\n",
    "# Función para crear histogramas\n",
    "def plot_distribution(dataframe, column):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=dataframe, x=column, kde=True)\n",
    "    plt.title(f'\\n\\nDistribución de {column.capitalize()}\\n')\n",
    "    plt.xlabel(column.capitalize())\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()\n",
    "\n",
    "# Crear histogramas para cada métrica RFM\n",
    "for column in ['recency', 'frequency', 'monetary']:\n",
    "    plot_distribution(rfm, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f21a0-33ba-441d-a3d2-a89817bc2998",
   "metadata": {},
   "source": [
    "- Distribución de Recency:\n",
    "\n",
    "La gráfica muestra una distribución asimétrica positiva (cola hacia la derecha).\n",
    "Hay una alta concentración de clientes con recency baja (cerca de 0), lo que indica que muchos clientes han realizado compras recientemente.\n",
    "Hay una cola larga hacia la derecha, lo que sugiere que algunos clientes no han comprado en mucho tiempo.\n",
    "\n",
    "- Distribución de Frequency:\n",
    "\n",
    "Muestra una distribución extremadamente asimétrica positiva (cola larga a la derecha).\n",
    "La gran mayoría de los clientes tienen una frecuencia de compra baja (cerca de 0).\n",
    "Hay unos pocos clientes con frecuencias de compra muy altas (hasta 7k+).\n",
    "\n",
    "\n",
    "- Distribución de Monetary:\n",
    "\n",
    "También presenta una distribución muy asimétrica positiva.\n",
    "La mayoría de los clientes tienen un valor monetario bajo.\n",
    "Hay algunos clientes con valores monetarios extremadamente altos (hasta 250,000+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c4f96-4ada-407d-a8e4-5ec9a7a5925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para cada métrica RFM\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, column in enumerate(['recency', 'frequency', 'monetary'], 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(y=rfm[column])\n",
    "    plt.title(f'Boxplot de {column.capitalize()}\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf5a56-2b49-4030-88dd-4cda370be7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada métrica RFM\n",
    "for column in ['recency', 'frequency', 'monetary']:\n",
    "    print(f\"\\n\\nEstadísticas para {column.capitalize()}:\\n\")\n",
    "    stats = rfm[column].describe(percentiles=[.25, .5, .75])\n",
    "    print(stats)\n",
    "    \n",
    "    # Cálculo del IQR y límites para outliers\n",
    "    Q1 = stats['25%']\n",
    "    Q3 = stats['75%']\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    print(f\"Límite inferior para outliers: {lower_bound}\")\n",
    "    print(f\"Límite superior para outliers: {upper_bound}\")\n",
    "    print(f\"Número de outliers inferiores: {sum(rfm[column] < lower_bound)}\")\n",
    "    print(f\"Número de outliers superiores: {sum(rfm[column] > upper_bound)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d2674-c362-4e16-bec4-4c2a2aa0d498",
   "metadata": {},
   "source": [
    "Gracias por proporcionar estos datos detallados. Vamos a analizarlos para cada métrica RFM:\n",
    "\n",
    "## Recency:\n",
    "   - La recencia media es de 91.61 días, con una mediana de 50 días.\n",
    "   - El 75% de los clientes han comprado en los últimos 141 días.\n",
    "   - Hay 155 clientes (3.57%) considerados outliers superiores, que no han comprado en más de 327 días.\n",
    "   - La distribución es asimétrica positiva (media > mediana), lo que indica una cola larga hacia la derecha.\n",
    "\n",
    "## Frequency:\n",
    "   - La frecuencia media de compra es 90.52, pero la mediana es solo 41, indicando una fuerte asimetría positiva.\n",
    "   - El 75% de los clientes han realizado 98 o menos compras.\n",
    "   - Hay 381 clientes (8.78%) considerados outliers superiores, con más de 219.5 compras.\n",
    "   - El máximo de 7676 compras sugiere la presencia de algunos clientes extremadamente frecuentes.\n",
    "\n",
    "## Monetary:\n",
    "   - El valor monetario medio es de 2048.69, pero la mediana es solo 668.57, indicando una fuerte asimetría positiva.\n",
    "   - El 75% de los clientes han gastado 1660.60 o menos.\n",
    "   - Hay 425 clientes (9.80%) considerados outliers superiores, gastando más de 3691.77.\n",
    "   - El máximo de 280,206.02 sugiere la presencia de algunos clientes de muy alto valor.\n",
    "\n",
    "## Conclusiones y recomendaciones:\n",
    "\n",
    "- Asimetría: Todas las métricas muestran una fuerte asimetría positiva, especialmente Frequency y Monetary. Esto refuerza la necesidad de una transformación logarítmica antes del clustering.\n",
    "\n",
    "- **Outliers**: Hay un número significativo de outliers superiores en todas las métricas, especialmente en Frequency y Monetary. Estos representan clientes de alto valor que merecen un análisis y tratamiento especial.\n",
    "\n",
    "- Segmentación: La gran diferencia entre la media y la mediana en Frequency y Monetary sugiere que una pequeña proporción de clientes contribuye significativamente al negocio. Una segmentación efectiva podría ayudar a identificar y manejar estos grupos de manera diferenciada.\n",
    "\n",
    "- Estrategias diferenciadas:\n",
    "   - Para clientes con alta recencia (>327 días), considerar campañas de reactivación.\n",
    "   - Para los outliers superiores en Frequency y Monetary, desarrollar programas de fidelización y retención especiales.\n",
    "   - Para la mayoría de los clientes (que están por debajo de la mediana en Frequency y Monetary), diseñar estrategias para aumentar su frecuencia de compra y valor.\n",
    "\n",
    "- Preparación para clustering:\n",
    "   - Aplicar transformación logarítmica a Frequency y Monetary.\n",
    "   - Normalizar todas las variables.\n",
    "   - Al interpretar los resultados del clustering, prestar especial atención a cómo se agrupan los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1981c-b4bc-4d3a-aaef-34d7da989fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(df, column):\n",
    "    # Calcular Q1 (primer cuartil) y Q3 (tercer cuartil)\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    # Calcular el Rango Intercuartílico (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    # Definir los límites para los outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Identificar los outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Identificar outliers para cada columna RFM\n",
    "for column in ['recency', 'frequency', 'monetary']:\n",
    "    outliers, lower, upper = identify_outliers(rfm, column)\n",
    "    print(f\"\\nOutliers en {column}:\")\n",
    "    print(f\"Número de outliers: {len(outliers)}\")\n",
    "    print(f\"Límite inferior: {lower}\")\n",
    "    print(f\"Límite superior: {upper}\")\n",
    "    display(outliers.head())\n",
    "\n",
    "def extreme_outliers(df, column, factor=3):\n",
    "    # Similar a identify_outliers, pero con un factor más extremo\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    extremes = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return extremes\n",
    "\n",
    "# Identificar outliers extremos para cada columna RFM\n",
    "for column in ['recency', 'frequency', 'monetary']:\n",
    "    extremes = extreme_outliers(rfm, column)\n",
    "    print(f\"\\nOutliers extremos en {column}\")\n",
    "    print(f\"Número de outliers extremos: {len(extremes)}\")\n",
    "    display(extremes.head())\n",
    "\n",
    "def plot_distribution_with_without_outliers(df, column):\n",
    "    # Identificar outliers\n",
    "    outliers, lower, upper = identify_outliers(df, column)\n",
    "    # Crear un DataFrame sin outliers\n",
    "    non_outliers = df[(df[column] >= lower) & (df[column] <= upper)]\n",
    "    \n",
    "    # Crear una figura con dos subplots\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Subplot para la distribución con outliers\n",
    "    plt.subplot(121)\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribución de {column} con outliers')\n",
    "    \n",
    "    # Subplot para la distribución sin outliers\n",
    "    plt.subplot(122)\n",
    "    sns.histplot(non_outliers[column], kde=True)\n",
    "    plt.title(f'Distribución de {column} sin outliers')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar la distribución con y sin outliers para cada columna RFM\n",
    "for column in ['recency', 'frequency', 'monetary']:\n",
    "    plot_distribution_with_without_outliers(rfm, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41bb01-19ae-4608-bf2f-1c3caa101e6a",
   "metadata": {},
   "source": [
    "### Distribuciones sin Outliers en Frequency y Monetary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc92a4-8225-4e51-a7ed-314c58e32b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para remover outliers\n",
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for column in columns:\n",
    "        Q1 = df_clean[column].quantile(0.25)\n",
    "        Q3 = df_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "# Actualizar rfm eliminando outliers de 'monetary' y 'frequency'\n",
    "rfm = remove_outliers(rfm, ['monetary', 'frequency'])\n",
    "\n",
    "# Imprimir información sobre el nuevo DataFrame\n",
    "print(\"\\n\")\n",
    "print(f\"Tamaño del DataFrame rfm actualizado: {len(rfm)}\")\n",
    "print(\"\\nEstadísticas descriptivas del rfm actualizado:\\n\")\n",
    "display(rfm.describe())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "sns.histplot(data=rfm, x='recency', kde=True)\n",
    "plt.title('Distribución de Recency')\n",
    "\n",
    "plt.subplot(132)\n",
    "sns.histplot(data=rfm, x='frequency', kde=True)\n",
    "plt.title('Distribución de Frequency (sin outliers)')\n",
    "\n",
    "plt.subplot(133)\n",
    "sns.histplot(data=rfm, x='monetary', kde=True)\n",
    "plt.title('Distribución de Monetary (sin outliers)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33581376-63f4-4652-8279-974aa2c1bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots para visualizar relaciones entre métricas\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "sns.scatterplot(data=rfm, x='recency', y='frequency')\n",
    "plt.title('Recency vs Frequency')\n",
    "plt.subplot(132)\n",
    "sns.scatterplot(data=rfm, x='recency', y='monetary')\n",
    "plt.title('Recency vs Monetary')\n",
    "plt.subplot(133)\n",
    "sns.scatterplot(data=rfm, x='frequency', y='monetary')\n",
    "plt.title('Frequency vs Monetary')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f94a8-bbae-4996-b145-a208317c9c14",
   "metadata": {},
   "source": [
    "- Recency vs Frequency: Muestra una concentración de puntos en la esquina inferior izquierda, indicando que muchos clientes tienen baja recencia y baja frecuencia. Hay algunos outliers con frecuencia muy alta.\n",
    "- Recency vs Monetary: Similar al anterior, con la mayoría de los puntos concentrados en valores bajos, pero con algunos outliers de alto valor monetario.\n",
    "- Frequency vs Monetary: Muestra una relación positiva más clara, con algunos clientes destacando por tener valores muy altos en ambas métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275c105-ce29-49b7-8b5a-ca87eed0e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "corr_matrix = rfm[['recency', 'frequency', 'monetary']].corr()\n",
    "\n",
    "print(\"\\nMatriz de correlación:\\n\")\n",
    "display(corr_matrix)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Función para describir la relación entre dos variables\n",
    "def describe_relationship(x, y, x_name, y_name):\n",
    "    print(f\"Relación entre {x_name} y {y_name}:\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Correlación: {x.corr(y):.4f}\")\n",
    "    print(f\"Covarianza: {x.cov(y):.4f}\")\n",
    "    print(f\"{x_name} - Media: {x.mean():.4f}, Desviación estándar: {x.std():.4f}\")\n",
    "    print(f\"{y_name} - Media: {y.mean():.4f}, Desviación estándar: {y.std():.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Describir las relaciones\n",
    "describe_relationship(rfm['recency'], rfm['frequency'], 'Recency', 'Frequency')\n",
    "describe_relationship(rfm['recency'], rfm['monetary'], 'Recency', 'Monetary')\n",
    "describe_relationship(rfm['frequency'], rfm['monetary'], 'Frequency', 'Monetary')\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(rfm.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Matriz de Correlación RFM\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62158c7b-a65b-47cd-ae70-3acf1fb0ad85",
   "metadata": {},
   "source": [
    "**Recency y Frequency:**\n",
    "- -La correlación es negativa (-0.3514), lo que indica que a medida que la Recency aumenta, la Frequency tiende a disminuir, y viceversa. Esto podría sugerir que los clientes que han comprado más recientemente tienden a hacer compras con menos frecuencia.\n",
    "\n",
    "**Recency y Monetary:**\n",
    "- La correlación también es negativa (-0.3275), lo que sugiere que los clientes que han comprado más recientemente tienden a gastar menos, y viceversa. Esto podría indicar que los clientes que gastan más tienden a hacerlo en compras menos frecuentes.\n",
    "\n",
    "**Frequency y Monetary:**\n",
    "- La correlación es positiva (0.6733), lo que indica que a medida que la Frequency aumenta, la Monetary también tiende a aumentar. Esto sugiere que los clientes que hacen compras con más frecuencia también tienden a gastar más en total.\n",
    "\n",
    "Estas son solo observaciones generales y podrían no aplicarse a todos los clientes. También es importante tener en cuenta otros factores que podrían influir en estas relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094859d8-3f72-4315-aff3-b06d3b2ce276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "display(rfm.describe())\n",
    "\n",
    "# Asimetría y curtosis\n",
    "print(\"\\nAsimetría:\")\n",
    "print(rfm.skew())\n",
    "print(\"\\nCurtosis:\")\n",
    "print(rfm.kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d627fa-923e-4cf9-bcd4-1afd969fdf3b",
   "metadata": {},
   "source": [
    "- La asimetría es una medida de la falta de simetría en la distribución de los datos. Un valor de asimetría **positivo** indica una distribución con cola a la derecha o sesgada a la derecha.\n",
    "\n",
    "- La curtosis es una medida de la **pesadez** de las colas de una distribución. En comparación con una distribución normal, un valor de curtosis positivo indica colas más pesadas (más propensas a tener valores extremos), mientras que un valor negativo indica colas más ligeras (menos propensas a tener valores extremos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ae00f-1dda-481a-81a2-8b80505116a0",
   "metadata": {},
   "source": [
    "### Segmentación de clientes (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd9bdf-9b24-44ac-8b35-11277c10d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar transformación logarítmica\n",
    "rfm['log_frequency'] = np.log1p(rfm['frequency'])\n",
    "rfm['log_monetary'] = np.log1p(rfm['monetary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539b83e-fa76-4ac3-98c4-8b48b7008459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con las variables transformadas\n",
    "rfm_normalized = rfm[['recency', 'log_frequency', 'log_monetary']].copy()\n",
    "\n",
    "# Normalizar las variables\n",
    "scaler = StandardScaler()\n",
    "rfm_normalized = pd.DataFrame(scaler.fit_transform(rfm_normalized), \n",
    "                              columns=['recency', 'log_frequency', 'log_monetary'], \n",
    "                              index=rfm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb030834-c459-4d76-af4b-cb559b8ba488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la inercia (suma de las distancias al cuadrado)\n",
    "def calculate_inertia(data, k_range):\n",
    "    inertias = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "    return inertias\n",
    "\n",
    "# Función para calcular el score de silueta\n",
    "def calculate_silhouette(data, k_range):\n",
    "    silhouette_scores = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "        score = silhouette_score(data, labels)\n",
    "        silhouette_scores.append(score)\n",
    "    return silhouette_scores\n",
    "\n",
    "# Rango de número de clusters a probar\n",
    "k_range = range(2, 25)\n",
    "\n",
    "# Calcular inercia y score de silueta\n",
    "inertias = calculate_inertia(rfm_normalized, k_range)\n",
    "silhouette_scores = calculate_silhouette(rfm_normalized, k_range)\n",
    "\n",
    "# Visualizar el método del codo\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(k_range, inertias, marker='o')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('Método del Codo')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(k_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Score de Silueta')\n",
    "plt.title('Método de la Silueta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe35fe-8645-471b-8bca-ea190fd4e0f2",
   "metadata": {},
   "source": [
    "\n",
    "**Número óptimo de clusters**\n",
    "\n",
    "El gráfico del método del codo muestra una disminución pronunciada de la inercia hasta aproximadamente 4-5 clusters, después de lo cual la disminución se vuelve más gradual. El gráfico del score de silueta muestra valores más altos para números menores de clusters, con un pico local alrededor de 4-5 clusters. Por lo que estableceremos optimal_k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9191d8d-2a05-46d9-9b60-4c8ae65c2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número óptimo de clusters\n",
    "optimal_k = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "rfm['Cluster'] = kmeans.fit_predict(rfm_normalized)\n",
    "\n",
    "# Añadir los clusters al DataFrame original\n",
    "rfm_with_clusters = rfm.copy()\n",
    "rfm_with_clusters['Cluster'] = rfm['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46e9ad-0dfa-4c41-8e15-d1ed7913f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas por cluster\n",
    "cluster_stats = rfm_with_clusters.groupby('Cluster').agg({\n",
    "    'recency': 'mean',\n",
    "    'frequency': 'mean',\n",
    "    'monetary': 'mean'\n",
    "})\n",
    "\n",
    "# Añadir el conteo de clientes por cluster\n",
    "cluster_stats['count'] = rfm_with_clusters.groupby('Cluster').size()\n",
    "\n",
    "print(\"\\nEstadísticas por cluster\\n\")\n",
    "display(cluster_stats)\n",
    "\n",
    "# Visualizar los clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(rfm_normalized['log_frequency'], \n",
    "                      rfm_normalized['log_monetary'], \n",
    "                      c=rfm['Cluster'], \n",
    "                      cmap='viridis')\n",
    "plt.xlabel('Log Frequency (Normalizado)')\n",
    "plt.ylabel('Log Monetary (Normalizado)')\n",
    "plt.title('Clusters de Clientes')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6ccd8-8be1-47ee-a92d-a3281ce6fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(rfm['recency'], rfm['frequency'], rfm['monetary'], \n",
    "                     c=rfm['Cluster'], cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary')\n",
    "plt.title('Visualización 3D de Clusters RFM')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n",
    "\n",
    "# Gráficos 2D\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "axes[0].scatter(rfm['recency'], rfm['frequency'], c=rfm['Cluster'], cmap='viridis')\n",
    "axes[0].set_xlabel('Recency')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Recency vs Frequency')\n",
    "\n",
    "axes[1].scatter(rfm['recency'], rfm['monetary'], c=rfm['Cluster'], cmap='viridis')\n",
    "axes[1].set_xlabel('Recency')\n",
    "axes[1].set_ylabel('Monetary')\n",
    "axes[1].set_title('Recency vs Monetary')\n",
    "\n",
    "axes[2].scatter(rfm['frequency'], rfm['monetary'], c=rfm['Cluster'], cmap='viridis')\n",
    "axes[2].set_xlabel('Frequency')\n",
    "axes[2].set_ylabel('Monetary')\n",
    "axes[2].set_title('Frequency vs Monetary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb37ba-dba3-409c-92c3-ac59c7051bfb",
   "metadata": {},
   "source": [
    "### Clientes de alto valor (Cluster 4):\n",
    "- **Estrategia**: Programas de fidelización, ofertas exclusivas, servicio premium.\n",
    "- **Objetivo**: Mantener su alta frecuencia de compra y aumentar el valor por compra.\n",
    "\n",
    "### Clientes activos de valor medio (Cluster 3):\n",
    "- **Estrategia**: Incentivos para aumentar el valor de compra, cross-selling.\n",
    "- **Objetivo**: Incrementar el valor monetario de sus compras.\n",
    "\n",
    "### Clientes recientes de bajo valor (Cluster 2):\n",
    "- **Estrategia**: Campañas para aumentar la frecuencia de compra, ofertas atractivas.\n",
    "- **Objetivo**: Convertirlos en clientes más frecuentes y de mayor valor.\n",
    "\n",
    "### Clientes de valor medio con baja recencia (Cluster 0):\n",
    "- **Estrategia**: Campañas de reactivación, ofertas personalizadas basadas en compras anteriores.\n",
    "- **Objetivo**: Reducir el tiempo desde la última compra y aumentar la frecuencia.\n",
    "\n",
    "### Clientes inactivos de bajo valor (Cluster 1):\n",
    "- **Estrategia**: Campañas de reactivación agresivas, encuestas para entender la inactividad.\n",
    "- **Objetivo**: Recuperar estos clientes o decidir si vale la pena invertir en ellos.\n",
    "\n",
    "**Observaciones generales:**\n",
    "\n",
    "Los clusters 3 y 4 (clientes activos y de alto valor) representan la mayor parte de la base de clientes (2115 de 3662, o 57.8%).\n",
    "Hay una clara diferenciación entre los segmentos en términos de comportamiento de compra.\n",
    "La recencia parece ser un factor importante en la segmentación, con una clara distinción entre clientes activos e inactivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75715475-6ab9-42e2-8aac-cd0d3bcc95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que tenemos información adicional como 'product_category' y 'purchase_month'\n",
    "for cluster in rfm['Cluster'].unique():\n",
    "    cluster_data = rfm[rfm['Cluster'] == cluster]\n",
    "    \n",
    "    print(f\"\\nAnálisis de Cluster {cluster}\")\n",
    "    print(f\"\\nEstadísticas RFM Cluster {cluster}\")\n",
    "    display(cluster_data[['recency', 'frequency', 'monetary']].describe())\n",
    "    print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270cfc3d-5900-46b3-abaf-6ecce5d01eb3",
   "metadata": {},
   "source": [
    "# Análisis de Clusters RFM\n",
    "\n",
    "## Resumen de Clusters\n",
    "\n",
    "| Cluster | Nombre | Recencia (días) | Frecuencia | Monetario ($) | Clientes |\n",
    "|---------|--------|-----------------|------------|---------------|----------|\n",
    "| 4 | Clientes de alto valor | 41 | 93.5 | 1669 | 1052 |\n",
    "| 3 | Clientes activos de valor medio | 48 | 36.7 | 601 | 1063 |\n",
    "| 2 | Clientes recientes de bajo valor | 67 | 10.5 | 226 | 594 |\n",
    "| 0 | Clientes de valor medio con baja recencia | 240 | 36.1 | 563 | 549 |\n",
    "| 1 | Clientes inactivos de bajo valor | 278 | 8.5 | 191 | 404 |\n",
    "\n",
    "## Análisis Detallado por Cluster\n",
    "\n",
    "### Cluster 4: Clientes de alto valor\n",
    "- **Características**: Muy activos, alta frecuencia, alto valor\n",
    "- **Estrategia**: Retención y maximización de valor\n",
    "- **Acciones**:\n",
    "  1. Implementar programa VIP exclusivo\n",
    "  2. Ofrecer acceso anticipado a nuevos productos\n",
    "  3. Proporcionar servicio al cliente dedicado\n",
    "\n",
    "### Cluster 3: Clientes activos de valor medio\n",
    "- **Características**: Activos, frecuencia media, valor medio\n",
    "- **Estrategia**: Incremento de valor por compra\n",
    "- **Acciones**:\n",
    "  1. Crear programa de escalado de compras\n",
    "  2. Ofrecer paquetes de productos para aumentar el valor por transacción\n",
    "  3. Desarrollar contenido educativo sobre productos premium\n",
    "\n",
    "### Cluster 2: Clientes recientes de bajo valor\n",
    "- **Características**: Recientes, baja frecuencia, bajo valor\n",
    "- **Estrategia**: Aumento de frecuencia y valor\n",
    "- **Acciones**:\n",
    "  1. Lanzar campaña de \"segunda compra\" con incentivos\n",
    "  2. Implementar sistema de recomendaciones personalizadas\n",
    "  3. Introducir programa de fidelización básico\n",
    "\n",
    "### Cluster 0: Clientes de valor medio con baja recencia\n",
    "- **Características**: Baja recencia, frecuencia media, valor medio\n",
    "- **Estrategia**: Reactivación personalizada\n",
    "- **Acciones**:\n",
    "  1. Desarrollar campaña \"te extrañamos\" con ofertas especiales\n",
    "  2. Enviar recordatorios de productos previamente comprados\n",
    "  3. Realizar encuesta para entender razones de inactividad\n",
    "\n",
    "### Cluster 1: Clientes inactivos de bajo valor\n",
    "- **Características**: Muy baja recencia, baja frecuencia, bajo valor\n",
    "- **Estrategia**: Recuperación y reactivación\n",
    "- **Acciones**:\n",
    "  1. Lanzar campaña de \"última oportunidad\" con descuentos significativos\n",
    "  2. Implementar programa de reactivación por etapas\n",
    "  3. Evaluar ROI de marketing para este grupo\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "1. Implementar sistema de puntuación RFM continuo\n",
    "2. Desarrollar campañas de marketing específicas por cluster\n",
    "3. Establecer KPIs para medir éxito de estrategias\n",
    "4. Realizar análisis de cohortes para seguimiento de evolución de clientes\n",
    "5. Incorporar datos adicionales para segmentación más precisa\n",
    "\n",
    "## Observaciones Finales de la Segmentación\n",
    "\n",
    "- Clara segmentación en términos de valor y actividad del cliente\n",
    "- Clusters 3 y 4 representan la mayoría de la base de clientes\n",
    "- Oportunidad de mover clientes entre clusters adyacentes\n",
    "- Urgencia en estrategias de reactivación para clusters 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d80345-9817-4593-abbd-e6432fbe531c",
   "metadata": {},
   "source": [
    "## Entrenamiento y pruebas de Modelos Predictivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d1d15-60cc-4cd2-94b8-ca0c939a9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos\n",
    "X = rfm.drop('Cluster', axis=1)\n",
    "y = rfm['Cluster']\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Máquina de Soporte Vectorial (SVM)\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# 2. K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 3. Árbol de Decisión\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# 5. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# 6. Ensamble de Votación\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), \n",
    "    ('knn', knn), \n",
    "    ('tree', tree), \n",
    "    ('gb', gb), \n",
    "    ('nb', nb)\n",
    "], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 7. Redes Neuronales Artificiales (MLP)\n",
    "mlp = MLPClassifier(random_state=42, max_iter=500)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 8. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "def imprimir_tabla_metricas(modelos, X_train, X_test, y_train, y_test):\n",
    "    metricas = {}\n",
    "    n_classes = len(np.unique(y_test))\n",
    "    is_binary = n_classes == 2\n",
    "    \n",
    "    for nombre, modelo in modelos.items():\n",
    "        # Medir tiempo de entrenamiento\n",
    "        start_train = time.time()\n",
    "        modelo.fit(X_train, y_train)\n",
    "        end_train = time.time()\n",
    "        train_time = end_train - start_train\n",
    "        \n",
    "        # Medir tiempo de prueba\n",
    "        start_test = time.time()\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        test_time = end_test - start_test\n",
    "        \n",
    "        if is_binary:\n",
    "            y_prob = modelo.predict_proba(X_test)[:, 1]\n",
    "            auc_roc = roc_auc_score(y_test, y_prob)\n",
    "        else:\n",
    "            y_prob = modelo.predict_proba(X_test)\n",
    "            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "            auc_roc = roc_auc_score(y_test_bin, y_prob, multi_class='ovr', average='macro')\n",
    "        \n",
    "        metricas[nombre] = {\n",
    "            'Precisión': precision_score(y_test, y_pred, average='macro'),\n",
    "            'Sensibilidad': recall_score(y_test, y_pred, average='macro'),\n",
    "            'F1-Score': f1_score(y_test, y_pred, average='macro'),\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'AUC-ROC': auc_roc,\n",
    "            'time_train': train_time,\n",
    "            'time_test': test_time\n",
    "        }\n",
    "    \n",
    "    # Crear tabla de métricas\n",
    "    df_metricas = pd.DataFrame(metricas).T\n",
    "    \n",
    "    # Convertir las métricas de rendimiento a porcentaje\n",
    "    metricas_porcentaje = ['Precisión', 'Sensibilidad', 'F1-Score', 'Accuracy', 'AUC-ROC']\n",
    "    df_metricas[metricas_porcentaje] = df_metricas[metricas_porcentaje] * 100\n",
    "    \n",
    "    # Reordenar las columnas\n",
    "    columnas_orden = ['Precisión', 'Sensibilidad', 'F1-Score', 'Accuracy', 'AUC-ROC', 'time_train', 'time_test']\n",
    "    df_metricas = df_metricas[columnas_orden]\n",
    "\n",
    "    # Función para formatear los valores sin ceros después del punto\n",
    "    def format_value(value):\n",
    "        if isinstance(value, float):\n",
    "            return f\"{value:.2f}\".rstrip('0').rstrip('.')\n",
    "        return value\n",
    "    \n",
    "    # Aplicar el formato a todas las celdas del DataFrame\n",
    "    df_metricas = df_metricas.map(format_value)\n",
    "    \n",
    "    # Ordenar el DataFrame por la columna 'Precisión' de mayor a menor\n",
    "    df_metricas_ordenado = df_metricas.sort_values(by='Precisión', ascending=False)\n",
    "    \n",
    "    # Mostrar la tabla ordenada usando display\n",
    "    display(df_metricas_ordenado.style.set_caption(\"Tabla de Métricas (rendimiento en porcentaje, tiempos en segundos) - Ordenada por Precisión\"))\n",
    "    \n",
    "    return df_metricas_ordenado\n",
    "\n",
    "def graficar_metrica(df_metricas, metrica):\n",
    "    # Convertir la columna seleccionada a tipo numérico\n",
    "    df_metricas[metrica] = pd.to_numeric(df_metricas[metrica])\n",
    "    \n",
    "    # Ordenar el DataFrame por la métrica seleccionada\n",
    "    df_sorted = df_metricas.sort_values(by=metrica, ascending=True)\n",
    "    \n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=df_sorted[metrica], y=df_sorted.index, palette='viridis')\n",
    "    \n",
    "    # Personalizar el gráfico\n",
    "    plt.title(f'Comparación de Modelos - {metrica}')\n",
    "    plt.xlabel('Valor de la Métrica')\n",
    "    plt.ylabel('Modelo')\n",
    "    \n",
    "    # Ajustar el rango del eje x según la métrica\n",
    "    if metrica in ['Precisión', 'Sensibilidad', 'F1-Score', 'Accuracy']:\n",
    "        plt.xlim(80, 100)\n",
    "    elif metrica == 'AUC-ROC':\n",
    "        plt.xlim(95, 100)\n",
    "    \n",
    "    # Añadir etiquetas de valor en las barras\n",
    "    for i, v in enumerate(df_sorted[metrica]):\n",
    "        ax.text(v, i, f' {v}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uso de las funciones\n",
    "modelos = {\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Voting': VotingClassifier(estimators=[\n",
    "        ('svm', SVC(probability=True, random_state=42)), \n",
    "        ('knn', KNeighborsClassifier()), \n",
    "        ('tree', DecisionTreeClassifier(random_state=42)), \n",
    "        ('gb', GradientBoostingClassifier(random_state=42)), \n",
    "        ('nb', GaussianNB())\n",
    "    ], voting='soft'),\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=500),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Imprimir tabla de métricas\n",
    "df_metricas = imprimir_tabla_metricas(modelos, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Graficar cada métrica\n",
    "for metrica in ['Precisión', 'Sensibilidad', 'F1-Score', 'Accuracy', 'AUC-ROC']:\n",
    "    graficar_metrica(df_metricas, metrica)\n",
    "\n",
    "# Graficar tiempos de entrenamiento y prueba\n",
    "graficar_metrica(df_metricas, 'time_train')\n",
    "graficar_metrica(df_metricas, 'time_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b304955-ddb1-4b5d-a98f-61816f2e8025",
   "metadata": {},
   "source": [
    "# Análisis de Rendimiento de Modelos de Clasificación\n",
    "\n",
    "## Resumen General\n",
    "Los datos muestran el rendimiento de 8 modelos de clasificación diferentes, evaluados en 5 métricas distintas. Todos los modelos muestran un rendimiento generalmente bueno, con valores superiores al 80% en todas las métricas.\n",
    "\n",
    "## Análisis por Modelo\n",
    "\n",
    "### Random Forest\n",
    "- **Mejor rendimiento general**\n",
    "- Líder en todas las 5 métricas (Precisión, Sensibilidad, F1-Score, Accuracy, AUC-ROC)\n",
    "- Rendimiento excepcionalmente equilibrado en todas las métricas\n",
    "- Tiempo de entrenamiento moderado y muy rápido en prueba \n",
    "\n",
    "### Gradient Boosting\n",
    "- Segundo mejor rendimiento general\n",
    "- Muy cercano al Random Forest en todas las métricas\n",
    "- Tiempo de entrenamiento largo, pero rápido en prueba \n",
    "\n",
    "### Voting (Ensamble de Votación)\n",
    "- Tercer mejor rendimiento\n",
    "- Muestra la fuerza de combinar múltiples modelos\n",
    "- Excelente AUC-ROC (99.79%)\n",
    "- Tiempo de entrenamiento más largo y rápido en prueba \n",
    "\n",
    "### Decision Tree (Árbol de Decisión)\n",
    "- Sorprendentemente buen rendimiento para un modelo relativamente simple\n",
    "- Cuarto en la mayoría de las métricas\n",
    "- Menor AUC-ROC entre los modelos de alto rendimiento (97.13%)\n",
    "- Extremadamente rápido en entrenamiento y prueba más rápida\n",
    "\n",
    "### MLP (Red Neuronal)\n",
    "- Rendimiento sólido pero no excepcional\n",
    "- Consistente en todas las métricas\n",
    "- Tiempo de entrenamiento moderado y muy rápido en prueba \n",
    "\n",
    "### Naive Bayes\n",
    "- Rendimiento sorprendentemente bueno para un modelo tan simple\n",
    "- Destaca en AUC-ROC (99.19%)\n",
    "- El más rápido en entrenamiento y prueba\n",
    "\n",
    "### KNN\n",
    "- Rendimiento moderado\n",
    "- Consistente en todas las métricas\n",
    "- Muy rápido en entrenamiento y prueba \n",
    "\n",
    "### SVM\n",
    "- Rendimiento más bajo en la mayoría de las métricas\n",
    "- Aún así, muestra un buen AUC-ROC (97.29%)\n",
    "- Tiempo de entrenamiento moderado y el más lento en prueba \n",
    "\n",
    "## Análisis por Métrica\n",
    "\n",
    "1. **Precisión**: Random Forest lidera (97.41%), seguido de cerca por Gradient Boosting (96.95%).\n",
    "2. **Sensibilidad**: Random Forest nuevamente en la cima (97.3%), con Gradient Boosting muy cerca (96.55%).\n",
    "3. **F1-Score**: Random Forest mantiene el liderazgo (97.34%), seguido por Gradient Boosting (96.72%).\n",
    "4. **Accuracy**: Random Forest continúa dominando (97.27%), con Gradient Boosting en segundo lugar (96.73%).\n",
    "5. **AUC-ROC**: Todos los modelos muestran un excelente rendimiento, con Random Forest liderando (99.94%), seguido muy de cerca por Gradient Boosting (99.89%) y Voting (99.79%).\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "1. **Random Forest** se destaca como el mejor modelo general, liderando en todas las métricas con un buen equilibrio entre rendimiento y tiempo de ejecución.\n",
    "2. **Gradient Boosting** es un fuerte competidor, muy cerca del rendimiento de Random Forest, pero con un tiempo de entrenamiento más largo.\n",
    "3. Los modelos de **ensemble** (Random Forest, Gradient Boosting, Voting) muestran un rendimiento superior, lo que sugiere que la combinación de múltiples modelos es efectiva para este conjunto de datos.\n",
    "4. Incluso los modelos más simples como **Decision Tree** y **Naive Bayes** muestran un rendimiento sorprendentemente bueno, especialmente considerando su velocidad.\n",
    "5. El alto rendimiento en **AUC-ROC** para todos los modelos sugiere que son capaces de distinguir bien entre las clases, independientemente del umbral de clasificación elegido.\n",
    "\n",
    "## Recomendaciones\n",
    "\n",
    "1. **Utilizar Random Forest** como modelo principal debido a su rendimiento superior, consistente y buen equilibrio entre rendimiento y tiempo de ejecución.\n",
    "2. Considerar **Gradient Boosting** como una alternativa sólida si el tiempo de entrenamiento no es una limitación crítica.\n",
    "3. Si la velocidad de inferencia o la interpretabilidad son importantes, el **Decision Tree** podría ser una opción viable dado su buen rendimiento y rapidez extrema.\n",
    "4. Para aplicaciones que requieran un balance entre rendimiento y simplicidad/velocidad, **Naive Bayes** podría ser una opción sorprendentemente efectiva.\n",
    "5. Realizar un análisis de las características más importantes utilizadas por Random Forest y Gradient Boosting para obtener insights sobre el problema de clasificación.\n",
    "6. Considerar el uso de **Voting** si se dispone de recursos computacionales suficientes, ya que ofrece un rendimiento muy alto, aunque con tiempos de ejecución más largos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
